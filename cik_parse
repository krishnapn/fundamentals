
## a loop for getting the content files of SEC filings that generates dictionary. CIK list is stored separtely for sanity and clarity. 

import urllib3
from bs4 import BeautifulSoup
import re
import re
import time 
import os
import numpy as np

d={}
for cik in list(finalCIK):
    url= 'https://www.sec.gov/Archives/edgar/data/'+cik
    http = urllib3.PoolManager()
    r = http.request('GET', url)
    soup=BeautifulSoup(r.data, 'html.parser')
    for i in soup.find_all('a'):
        if len(str(i['href']).split('/')) ==6:
            if i['href'].split('/')[-2] == cik:
                d.setdefault(cik,[]).append(i['href'])
